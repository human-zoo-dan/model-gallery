name: "mistral"

description: |
  This is a mistral model

license: "https://ai.meta.com/llama/license/"
urls:
- https://huggingface.co/TheBloke/Mistral-7B-OpenOrca-GGUF

config_file: |
  name: mixtral
  context_size: 8192
  f16: true
  mmap: true
  gpu_layers: 35
  threads: 16
  parameters:
    model: dolphin-2.7-mixtral-8x7b.Q3_K_M.gguf
    temperature: 0.2
    top_k: 40
    top_p: 0.95
  template:
    chat_message: chatml
    chat: chatml-block
    completion: completion
  stopwords:
  - <|im_end|>

prompt_templates:
- name: "chatml"
  content: |
    <|im_start|>{{if eq .RoleName "assistant"}}assistant{{else if eq .RoleName "system"}}system{{else if eq .RoleName "user"}}user{{end}}
    {{if .Content}}{{.Content}}{{end}}
    <|im_end|>
- name: "chatml-block"
  content: |
    {{.Input}}
    <|im_start|>assistant
- name: "completion"
  content: |
    {{.Input}}
    
files:
- filename: "dolphin-2.7-mixtral-8x7b.Q3_K_M.gguf"
  sha256: "b773e8f5456c382a61f75c32126ffa851608a5d85673779d5068a410886a9980"
  uri: "https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q3_K_M.gguf"
